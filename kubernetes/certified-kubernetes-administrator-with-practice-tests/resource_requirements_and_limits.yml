El scheduler tiene en cuenta los recursos (cpu, ram, disco) que consume
el POD y los disponibles en el NODO. SI el nodo no tiene
suficientes recursos, evita meter el POD ahi.

Si no entra en ningun NODO, entonces queda Pending
(ej de Pending: Insufficient cpu)

Default (resoruce requests):
  cpu: 0.5
  mem: 256Mi

Para que el POD use estos valores por defecto, primero
debimos haber seteado estos valores para request y limitarlos
creando un LimitRange en el namespace

    # apiVersion: v1
    # kind: LimitRange
    # metadata:
    #   name: mem-limit-range
    # spec:
    #   limits:
    #   - default:
    #       memory: 512Mi
    #     defaultRequest:
    #       memory: 256Mi
    #     type: Container

    # apiVersion: v1
    # kind: LimitRange
    # metadata:
    #   name: cpu-limit-range
    # spec:
    #   limits:
    #   - default:
    #       cpu: 1
    #     defaultRequest:
    #       cpu: 0.5
    #     type: Container


apiVersion: v1
kind: Pod
metadata:
  name: simple-webapp-color
  labels:
    name: simple-webapp-color
spec:
  containers:
    - name: simple-webapp-color
      image: simple-webapp-color
      ports:
        - containerPort: 8080
      resources:
        requests:
          memory: "1Gi"
          cpu: 1


Resource - CPU:
---------------

0.1cpu == 100m CPU  -- m -> milli. Minimo se puede setear 1m

1 CPU == 1 AWS vCPU
1 CPU == 1 GCP Core
1 CPU == 1 Azure Core
1 CPU == 1 Hyperthread

Resources - Memory
------------------
1G(Gigabyte) = 1.000.000.000 bytes
1Gi(Gibibyte) = 1.073.741.824 bytes

1K = 1000 bytes
1Ki = 1024 bytes


containers - limites
---------------------
Los containers pueden crecer en recursos si no los especifico.
Por defecto asigna hasta 1vCPU si no lo especifico.
Por defecto asigna 512Mi por container

requests y limits son seteados por cada container
spec:
  containers:
    - name: simple-webapp-color
      image: simple-webapp-color
      ports:
        - containerPort: 8080
      resources:
        requests:
          memory: "1Gi"
          cpu: 1
        limits:
          memory: "2Gi"
          cpu: 2

El cpu es truncado si el POD trata de pedir mas que su limite (throttle)
pero la memoria puede ser superada. Si el POD trata de consumir
mas memoria que su limite CONSTANTEMENTE, entonces es TERMINADO.


status 'OOMKilled' indicates that the pod ran out of memory

DaemonSets
----------

Ayuda al deploy de instancias multiples de pods pero instancia
1 copia del pod en cada NODO. Si se agrega un nodo al cluster, 
una replica es automaticamente instanciada y cuando el nodo es 
removido, el pod es automaticamente eliminado

Casos de Uso:
-------------

- Monitoring Solution
- Logs Viewer

En ambos casos necesito 1 pod en c/nodo que quiero monitorear o loggear

[daemon-set-definition.yaml]

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: monitoring-daemon
spec:
  selector:
    matchLabels:
      app: monitoring-agent
    template:
      metadata:
        labels:
          app: monitoring-agent
      spec:
        containers:
          - name: monitoring-agent
            image: monitoring-agent

kubectl create -f daemon-set-definition.yaml
kubectl get daemonsets

Ubica los pods en cada nodo usando nodeAffinity


Static Pods
-----------

La idea es que kubelet tiene harcodeado en parte de su archivo
de inicio del servicio un path de directorio donde busca yml
y crea y mantiene pods. Se llaman Pods estaticos. Tambien
crea pods a pedido de kube-apiserver, estas son sus 2 habilidades.
Si el nodo es parte de un cluster, le avisa a la api de sus pods
estaticos. Puedo ver estos pods static con kubectl get pod, pero 
no los puedo editar o borrar como un pod clasico. Se borran 
si borro el yml del path que lee el kubelet
Los nombres de estos pods se le auto apendea el nombre del nodo.
Ej: static-web-node01

Caso de uso:
  Por ejemplo para generar masters. Es decir, para instalar los
  pods de apiserver, controller-manager, etcd.
  Asi es como kube-admin genera un cluster


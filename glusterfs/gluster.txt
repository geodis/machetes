
# yum install -y centos-release-gluster
# yum install -y glusterfs-server
# systemctl start glusterd
# gluster peer status
# gluster peer probe gluster2
# gluster peer status
# Number of Peers: 1

# cliente
#  yum install -y centos-release-gluster
# yum install -y glusterfs-client

# Crear volumenes - directorios de bricks
# en ambos servers: mkdir /gluster (este directorio tiene que estar en una particion individual no la de /)
# g1: gluster volume list
# la cantidad de replicas maximas es la cantidad de nodos (debe ser impar >=3 split-brain)
# tantos bricks como replicas. Puede ejecutarse en cualquier server
# g1o2: gluster volume create volume1 replica 2 gluster1:/gluster/brick1 gluster2:/gluster/brick1

# la 
# gluster volume create volume1 replica 2 gluster1:/gluster/brick1 gluster2:/gluster/brick1 force

# para accederlo necesito startearlo
# gluster volume start volume1

# -------------------------------------
# acceso desde el cliente
# mount -t glusterfs gluster1:volume1 /mnt/volume1/

# Borrar el volumen
# desmontar del cliente
# gluster volume stop volume1
# gluster volume delete volume1
# manualmente borrar los archivos en c/server

# Distribuido - si no le pongo reclicas es distribuido por defecto
# gluster volume create volume2 gluster1:/gluster/brick2 gluster2:/gluster/brick2 force
# 192.168.122.121 gluster3


gluster volume create test-volume replica 3 transport tcp 
server1:/exp1 
server2:/exp2 
server3:/exp3 
server4:/exp4 
server5:/exp5 
server6:/exp6


Listing Servers
To list all nodes in the TSP:


server1# gluster pool list

Removing Servers
To remove a server from the TSP, run the following command from another server in the pool:


# gluster peer detach <server>



Heketi

yum -y install heketi
sudo -u heketi ssh-keygen
vi /etc/heketi/heketi.json


  "jwt": {
    "_admin": "Admin has access to all APIs",
    "admin": {
      "key": "admin"
    },
    "_user": "User only has access to /volumes endpoint",
    "user": {
      "key": "user"
    }




 "executor": "ssh",

    "_sshexec_comment": "SSH username and private key file information",
    "sshexec": {
      "keyfile": "/var/lib/heketi/.ssh/id_rsa",
      "user": "root",
      "port": "22",
      "fstab": "/etc/fstab"
    },

systemctl enable --now heketi

# test
curl http://127.0.0.1:8080/hello

cat /var/lib/heketi/.ssh/id_rsa.pub 

copiar la key en c/nodo en /root/.ssh/authorized_keys

yum -y install heketi-client
En nodo donde este el heketi server

echo 'HEKETI_CLI_SERVER=http://localhost:8080' >> /etc/environment

Crear el cluster

heketi-cli cluster create mycluster
Cluster id: b197fce6f47c41bb70926018f94527e0


heketi-cli node add --cluster=b197fce6f47c41bb70926018f94527e0 --zone=1 --management-host-name=gluster1 --storage-host-name=gluster1
Node information:
Id: 20a3fbb360eab2a9ff5e44cc5d1c0d66
State: online
Cluster Id: b197fce6f47c41bb70926018f94527e0
Zone: 1
Management Hostname gluster1
Storage Hostname gluster1

heketi-cli node add --cluster=b197fce6f47c41bb70926018f94527e0 --zone=1 --management-host-name=gluster2 --storage-host-name=gluster2
Node information:
Id: 49d8609ddace25226377a8fce982bca1
State: online
Cluster Id: b197fce6f47c41bb70926018f94527e0
Zone: 1
Management Hostname gluster2
Storage Hostname gluster2


Agrego devices

# en g1
wipefs -a /dev/vdb1
heketi-cli device add --name=/dev/vdb1 --node=20a3fbb360eab2a9ff5e44cc5d1c0d66

# en g2
wipefs -a /dev/vdb1

Create volume 1G

# heketi-cli volume create --size=1 --replica=2
Name: vol_5cfe7046c8511aadf88fbe54fbf494e5
Size: 1
Volume Id: 5cfe7046c8511aadf88fbe54fbf494e5
Cluster Id: b197fce6f47c41bb70926018f94527e0
Mount: gluster1:vol_5cfe7046c8511aadf88fbe54fbf494e5
Mount Options: backup-volfile-servers=gluster2
Block: false
Free Size: 0
Reserved Size: 0
Block Hosting Restriction: (none)
Block Volumes: []
Durability Type: replicate
Distribute Count: 1
Replica Count: 2


mount -t glusterfs -o backup-volfile-servers=gluster2 gluster1:vol_5cfe7046c8511aadf88fbe54fbf494e5 mnt
